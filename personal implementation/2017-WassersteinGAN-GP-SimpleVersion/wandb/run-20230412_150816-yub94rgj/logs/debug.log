2023-04-12 15:08:16,640 INFO    MainThread:13584 [wandb_setup.py:_flush():76] Configure stats pid to 13584
2023-04-12 15:08:16,640 INFO    MainThread:13584 [wandb_setup.py:_flush():76] Loading settings from C:\Users\Administrator\.config\wandb\settings
2023-04-12 15:08:16,640 INFO    MainThread:13584 [wandb_setup.py:_flush():76] Loading settings from C:\Users\Administrator\OneDrive\Documents\Deep learning\Super Resolution\Models\2017-WassersteinGAN-GP-SimpleVersion\wandb\settings
2023-04-12 15:08:16,640 INFO    MainThread:13584 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-04-12 15:08:16,640 INFO    MainThread:13584 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-04-12 15:08:16,641 INFO    MainThread:13584 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'main.py', 'program': 'C:\\Users\\Administrator\\OneDrive\\Documents\\Deep learning\\Super Resolution\\Models\\2017-WassersteinGAN-GP-SimpleVersion\\main.py'}
2023-04-12 15:08:16,641 INFO    MainThread:13584 [wandb_init.py:_log_setup():507] Logging user logs to C:\Users\Administrator\OneDrive\Documents\Deep learning\Super Resolution\Models\2017-WassersteinGAN-GP-SimpleVersion\wandb\run-20230412_150816-yub94rgj\logs\debug.log
2023-04-12 15:08:16,641 INFO    MainThread:13584 [wandb_init.py:_log_setup():508] Logging internal logs to C:\Users\Administrator\OneDrive\Documents\Deep learning\Super Resolution\Models\2017-WassersteinGAN-GP-SimpleVersion\wandb\run-20230412_150816-yub94rgj\logs\debug-internal.log
2023-04-12 15:08:16,641 INFO    MainThread:13584 [wandb_init.py:init():547] calling init triggers
2023-04-12 15:08:16,641 INFO    MainThread:13584 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
config: {'architecture': 'WGAN', 'dataset': 'another anime face dataset', 'samples_num': 50000, 'learning_rate': 0.0001, 'Generator': 'Generator(\n  (layers): Sequential(\n    (0): ConvTranspose2d(100, 768, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): ConvTranspose2d(768, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): ConvTranspose2d(192, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n    (9): ConvTranspose2d(48, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (10): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): ReLU(inplace=True)\n    (12): PixelShuffle(upscale_factor=2)\n    (13): Tanh()\n  )\n)', 'Discriminator': 'Discriminator(\n  (layers): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n    (8): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n  )\n)', 'epochs': 15, 'batch_size': 64, 'optimizer_G': <class 'torch.optim.adam.Adam'>, 'betas_G': (0.5, 0.999), 'optimizer_D': <class 'torch.optim.adam.Adam'>, 'betas_D': (0.5, 0.999)}
2023-04-12 15:08:16,641 INFO    MainThread:13584 [wandb_init.py:init():595] starting backend
2023-04-12 15:08:16,641 INFO    MainThread:13584 [wandb_init.py:init():599] setting up manager
2023-04-12 15:08:16,644 INFO    MainThread:13584 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn, using: spawn
2023-04-12 15:08:16,648 INFO    MainThread:13584 [wandb_init.py:init():605] backend started and connected
2023-04-12 15:08:16,649 INFO    MainThread:13584 [wandb_init.py:init():695] updated telemetry
2023-04-12 15:08:16,652 INFO    MainThread:13584 [wandb_init.py:init():732] communicating run to backend with 60.0 second timeout
2023-04-12 15:08:17,502 INFO    MainThread:13584 [wandb_run.py:_on_init():2176] communicating current version
2023-04-12 15:08:18,287 INFO    MainThread:13584 [wandb_run.py:_on_init():2185] got version response 
2023-04-12 15:08:18,288 INFO    MainThread:13584 [wandb_init.py:init():782] starting run threads in backend
2023-04-12 15:08:27,247 INFO    MainThread:13584 [wandb_run.py:_console_start():2157] atexit reg
2023-04-12 15:08:27,247 INFO    MainThread:13584 [wandb_run.py:_redirect():2012] redirect: SettingsConsole.WRAP_RAW
2023-04-12 15:08:27,247 INFO    MainThread:13584 [wandb_run.py:_redirect():2077] Wrapping output streams.
2023-04-12 15:08:27,247 INFO    MainThread:13584 [wandb_run.py:_redirect():2102] Redirects installed.
2023-04-12 15:08:27,248 INFO    MainThread:13584 [wandb_init.py:init():824] run started, returning control to user process
2023-04-12 15:24:18,106 WARNING MsgRouterThr:13584 [router.py:message_loop():77] message_loop has been closed


Epoch: 1:   0%|                                                          | 0/516792 [00:23<?, ?it/s]
Traceback (most recent call last):
  File "H:\Deep-learning-exercises\personal implementation\thesis\train.py", line 159, in <module>
    hr_images = model(lr_images)
  File "D:\Anaconda\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "H:\Deep-learning-exercises\personal implementation\thesis\model0.py", line 170, in forward
    x8 = self.act2(self.conv2(x7))
  File "D:\Anaconda\lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Anaconda\lib\site-packages\torch\nn\modules\conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "D:\Anaconda\lib\site-packages\torch\nn\modules\conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [96, 64, 3, 3], expected input[16, 32, 128, 128] to have 64 channels, but got 32 channels instead